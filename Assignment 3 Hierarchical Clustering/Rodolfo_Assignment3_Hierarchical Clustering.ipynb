{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3: Hierarchical Clustering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Retrieve and load the Olivetti faces dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces\n",
    "\n",
    "# Load Olivetti faces dataset\n",
    "data = fetch_olivetti_faces(shuffle=True, random_state=86)\n",
    "X, y = data.data, data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split the training set, a validation set, and a test set using stratified sampling to ensure that there are the same number of images per person in each set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 60% training, 20% validation, 20% test\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, stratify=y, random_state=86)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=86)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Using k-fold cross validation, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.91666667 0.875      0.9375     0.89583333 0.9375    ]\n",
      "\n",
      "Mean cross-validation accuracy: 0.9125\n",
      "\n",
      "Validation score: 0.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "# Initialize the classifier\n",
    "clf = SVC(kernel='linear', random_state=86)\n",
    "\n",
    "# Perform k-fold cross-validation\n",
    "skf = StratifiedKFold(n_splits=5)\n",
    "scores = cross_val_score(clf, X_train, y_train, cv=skf)\n",
    "\n",
    "# Train on the full training set and evaluate on the validation set\n",
    "clf.fit(X_train, y_train)\n",
    "val_score = clf.score(X_val, y_val)\n",
    "\n",
    "print(f'Cross-validation scores: {scores}')\n",
    "print()\n",
    "print(\"Mean cross-validation accuracy:\", np.mean(scores))\n",
    "print()\n",
    "print(f'Validation score: {val_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Using either Agglomerative Hierarchical Clustering (AHC) or Divisive Hierarchical Clustering (DHC) and using the centroid-based clustering rule, reduce the dimensionality of the set by using the following similarity measures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of clusters (Euclidean): 77 with silhouette score: 0.1895388662815094\n",
      "Optimal number of clusters (Minkowski): 77 with silhouette score: 0.18953886830575567\n",
      "Optimal number of clusters (Cosine): 2 with silhouette score: 0.3219642639160156\n"
     ]
    }
   ],
   "source": [
    "# Determine the optimal number of clusters for each similarity measure using silhouette_score\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def find_optimal_clusters(X, metric):\n",
    "    best_score = -1\n",
    "    best_n_clusters = 2\n",
    "    for n_clusters in range(2, 80):\n",
    "        distance_matrix = pairwise_distances(X, metric=metric)\n",
    "        clustering = AgglomerativeClustering(n_clusters=n_clusters, metric='precomputed', linkage='average')\n",
    "        labels = clustering.fit_predict(distance_matrix)\n",
    "        score = silhouette_score(distance_matrix, labels, metric='precomputed')\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_n_clusters = n_clusters\n",
    "    return best_n_clusters, best_score\n",
    "\n",
    "optimal_clusters_euclidean, best_score_euclidean = find_optimal_clusters(X_train, 'euclidean')\n",
    "optimal_clusters_minkowski, best_score_minkowski = find_optimal_clusters(X_train, 'minkowski')\n",
    "optimal_clusters_cosine, best_score_cosine = find_optimal_clusters(X_train, 'cosine')\n",
    "\n",
    "print(f\"Optimal number of clusters (Euclidean): {optimal_clusters_euclidean} with silhouette score: {best_score_euclidean}\")\n",
    "print(f\"Optimal number of clusters (Minkowski): {optimal_clusters_minkowski} with silhouette score: {best_score_minkowski}\")\n",
    "print(f\"Optimal number of clusters (Cosine): {optimal_clusters_cosine} with silhouette score: {best_score_cosine}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* a) Euclidean Distance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform clustering and transform the data using the optimal number of clusters using the Euclidean Distance Approach:\n",
    "distance_matrix_euclidean = pairwise_distances(X_train, metric='euclidean')\n",
    "clustering_euclidean = AgglomerativeClustering(n_clusters=optimal_clusters_euclidean, metric='precomputed', linkage='complete')\n",
    "labels_euclidean = clustering_euclidean.fit_predict(distance_matrix_euclidean)\n",
    "\n",
    "centroids_euclidean = np.array([X_train[labels_euclidean == i].mean(axis=0) for i in range(optimal_clusters_euclidean)])\n",
    "X_train_transformed_euclidean = np.array([centroids_euclidean[label] for label in labels_euclidean])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* b) Minkowski Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_minkowski = pairwise_distances(X_train, metric='minkowski', p=3)\n",
    "clustering_minkowski = AgglomerativeClustering(n_clusters=optimal_clusters_minkowski, metric='precomputed', linkage='average')\n",
    "labels_minkowski = clustering_minkowski.fit_predict(distance_matrix_minkowski)\n",
    "\n",
    "centroids_minkowski = np.array([X_train[labels_minkowski == i].mean(axis=0) for i in range(optimal_clusters_minkowski)])\n",
    "X_train_transformed_minkowski = np.array([centroids_minkowski[label] for label in labels_minkowski])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* c) Cosine Similarity [20 points]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_matrix_cosine = pairwise_distances(X_train, metric='cosine')\n",
    "clustering_cosine = AgglomerativeClustering(n_clusters=optimal_clusters_cosine, metric='precomputed', linkage='average')\n",
    "labels_cosine = clustering_cosine.fit_predict(distance_matrix_cosine)\n",
    "\n",
    "centroids_cosine = np.array([X_train[labels_cosine == i].mean(axis=0) for i in range(optimal_clusters_cosine)])\n",
    "X_train_transformed_cosine = np.array([centroids_cosine[label] for label in labels_cosine])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Discuss any discrepancies observed between 4(a), 4(b), or 4(c).\n",
    "* Use the silhouette score approach to choose the number of clusters for 4(a), 4(b), and 4(c). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Use the set from (4(a), 4(b), or 4(c)) to train a classifier as in (3) using k-fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores (Euclidean): [0.83333333 0.6875     0.8125     0.75       0.8125    ]\n",
      "Mean cross-validation score (Euclidean): 0.7791666666666667\n",
      "\n",
      "Cross-validation scores (Minkowski): [0.64583333 0.64583333 0.6875     0.64583333 0.72916667]\n",
      "Mean cross-validation score (Minkowski): 0.6708333333333333\n",
      "\n",
      "Cross-validation scores (Cosine): [0.02083333 0.04166667 0.04166667 0.02083333 0.02083333]\n",
      "Mean cross-validation score (Cosine): 0.029166666666666664\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the classifier using the transformed datasets:\n",
    "def train_and_evaluate_classifier(X, y):\n",
    "    n_splits = max(2, min(5, np.min(np.bincount(y))))\n",
    "    kf = StratifiedKFold(n_splits=n_splits)\n",
    "    clf_svm = SVC(kernel='poly', random_state=42)\n",
    "    cv_scores = cross_val_score(clf_svm, X, y, cv=kf)\n",
    "    clf_svm.fit(X, y)  # Train the classifier on the full training set\n",
    "    return cv_scores, clf_svm\n",
    "\n",
    "# Train and evaluate classifier for each transformed dataset\n",
    "cv_scores_euclidean, clf_svm_euclidean = train_and_evaluate_classifier(X_train_transformed_euclidean, y_train)\n",
    "cv_scores_minkowski, clf_svm_minkowski = train_and_evaluate_classifier(X_train_transformed_minkowski, y_train)\n",
    "cv_scores_cosine, clf_svm_cosine = train_and_evaluate_classifier(X_train_transformed_cosine, y_train)\n",
    "\n",
    "print(f\"Cross-validation scores (Euclidean): {cv_scores_euclidean}\")\n",
    "print(f\"Mean cross-validation score (Euclidean): {np.mean(cv_scores_euclidean)}\")\n",
    "print()\n",
    "print(f\"Cross-validation scores (Minkowski): {cv_scores_minkowski}\")\n",
    "print(f\"Mean cross-validation score (Minkowski): {np.mean(cv_scores_minkowski)}\")\n",
    "print()\n",
    "print(f\"Cross-validation scores (Cosine): {cv_scores_cosine}\")\n",
    "print(f\"Mean cross-validation score (Cosine): {np.mean(cv_scores_cosine)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score (Euclidean): 0.025\n",
      "Validation score (Minkowski): 0.0375\n",
      "Validation score (Cosine): 0.025\n"
     ]
    }
   ],
   "source": [
    "# Evaluation the classifier on the Validation Set transformed:\n",
    "\n",
    "# Transform the validation set using the cluster centroids\n",
    "X_val_transformed_euclidean = np.array([centroids_euclidean[label] for label in clustering_euclidean.fit_predict(pairwise_distances(X_val, metric='euclidean'))])\n",
    "X_val_transformed_minkowski = np.array([centroids_minkowski[label] for label in clustering_minkowski.fit_predict(pairwise_distances(X_val, metric='minkowski', p=3))])\n",
    "X_val_transformed_cosine = np.array([centroids_cosine[label] for label in clustering_cosine.fit_predict(pairwise_distances(X_val, metric='cosine'))])\n",
    "\n",
    "# Evaluate the classifier on the transformed validation set\n",
    "val_score_euclidean = clf_svm_euclidean.score(X_val_transformed_euclidean, y_val)\n",
    "val_score_minkowski = clf_svm_minkowski.score(X_val_transformed_minkowski, y_val)\n",
    "val_score_cosine = clf_svm_cosine.score(X_val_transformed_cosine, y_val)\n",
    "\n",
    "print(f'Validation score (Euclidean): {val_score_euclidean}')\n",
    "print(f'Validation score (Minkowski): {val_score_minkowski}')\n",
    "print(f'Validation score (Cosine): {val_score_cosine}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
